{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eiDWcM_MC3H"
      },
      "source": [
        "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfe2NTQtLq11"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk5DSPCLxqT-"
      },
      "source": [
        "<font color='red'> Importing packages</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "42Et8BKIxnsp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpSk3WQBx7TQ"
      },
      "source": [
        "<font color='red'>Creating custom dataset</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BsMp0oWzx6dv"
      },
      "outputs": [],
      "source": [
        "# please don't change random_state\n",
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
        "# make_classification is used to create custom dataset \n",
        "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8W2fg1cyGdX",
        "outputId": "e6b75ced-5f47-48dd-8a9f-c33f4efea266"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x99RWCgpqNHw"
      },
      "source": [
        "<font color='red'>Splitting data into train and test </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Kh4dBfVyJMP"
      },
      "outputs": [],
      "source": [
        "#please don't change random state\n",
        "# you need not standardize the data as it is already standardized\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DR_YMBsyOci",
        "outputId": "918610d9-79e7-4344-915b-a50e167e4795"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4OHswfqjHR"
      },
      "source": [
        "# <font color='red' size=5>SGD classifier</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HpvTwDHyQQy",
        "outputId": "e3fd298c-5503-4f97-b177-eb964201cbf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
              "              random_state=15, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYaVyQ2lyXcr",
        "outputId": "5a76d668-8466-4cb5-e97b-28054134b5ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
            "Total training time: 0.12 seconds.\n",
            "Convergence after 10 epochs took 0.12 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
              "              random_state=15, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "clf.fit(X=X_train, y=y_train) # fitting our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAfkVI6GyaRO"
      },
      "outputs": [],
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_\n",
        "#clf.coef_ will return the weights\n",
        "#clf.coef_.shape will return the shape of weights\n",
        "#clf.intercept_ will return the intercept term"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-CcGTKgsMrY"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1_8bdzitDlM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1.  We will be giving you some functions, please write code in that functions only.\n",
        "\n",
        "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2Y3-FQuJ3z"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
        "\n",
        "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
        "- for each epoch:\n",
        "\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
        "\n",
        "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
        "\n",
        "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "\n",
        "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
        "\n",
        "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
        "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_HgjgS_wKu"
      },
      "source": [
        "<font color='blue'>Initialize weights </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GecwYV9fsKZ9"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(row_vector):\n",
        "  w = np.zeros_like(row_vector)\n",
        "  b = 0 \n",
        "  return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A7I6uWBRsKc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0374e328-ffc6-4b3b-8674-7a28dc26acbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "b = 0\n"
          ]
        }
      ],
      "source": [
        "dim=X_train[0] \n",
        "# Change initialize_weights(row_vector) to initialize_weights(dim) \n",
        "w,b = initialize_weights(dim)\n",
        "print('w =',(w))\n",
        "print('b =',str(b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MI5SAjP9ofN"
      },
      "source": [
        "<font color='red'>Grader function - 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Pv1llH429wG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd67333d-27ce-45e4-b736-7d13d9095eec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "def grader_weights(w,b):\n",
        "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
        "  return True\n",
        "grader_weights(w,b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN83oMWy_5rv"
      },
      "source": [
        "<font color='blue'>Compute sigmoid </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPv4NJuxABgs"
      },
      "source": [
        "$sigmoid(z)= 1/(1+exp(-z))$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nAfmQF47_Sd6"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  sigmoid = 1/(1+math.exp(-z))\n",
        "  return sigmoid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YrGDwg3Ae4m"
      },
      "source": [
        "<font color='red'>Grader function - 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P_JASp_NAfK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d851c6-6504-4bf6-9370-2ba68e412feb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def grader_sigmoid(z):\n",
        "  val=sigmoid(z)\n",
        "  assert(val==0.8807970779778823)\n",
        "  return True\n",
        "grader_sigmoid(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7JXbcrBOFF"
      },
      "source": [
        "<font color='blue'> Compute loss </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEiS22zBVYy"
      },
      "source": [
        "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VaFDgsp3sKi6"
      },
      "outputs": [],
      "source": [
        "def logloss(y_true,y_pred):\n",
        "  loss_array = np.add((np.multiply(y_true,np.log10(y_pred))),(np.multiply(np.subtract(1,y_true),np.log10(np.subtract(1,y_pred)))))\n",
        "  loss = -1 * ((np.sum(loss_array))/len(y_true))\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs1BTXVSClBt"
      },
      "source": [
        "<font color='red'>Grader function - 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LzttjvBFCuQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2532833a-7f11-4751-c55f-09cfc67b3f40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#round off the value to 8 values\n",
        "def grader_logloss(true,pred):\n",
        "  loss=logloss(true,pred)\n",
        "  assert(np.round(loss,6)==0.076449)\n",
        "  return True\n",
        "true=np.array([1,1,0,1,0])\n",
        "pred=np.array([0.9,0.8,0.1,0.8,0.2])\n",
        "grader_logloss(true,pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQabIadLCBAB"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to  'w' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMxiYKaCQgd"
      },
      "source": [
        "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NMVikyuFsKo5"
      },
      "outputs": [],
      "source": [
        "#make sure that the sigmoid function returns a scalar value, you can use dot function operation\n",
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "  w = w.reshape(w.shape+(1,))\n",
        "  x = x.reshape(x.shape+(1,))\n",
        "  w_t = np.transpose(w)\n",
        "  sigmoid_v  = sigmoid((np.matmul(w_t,x))+b)\n",
        "  db = y - sigmoid_v\n",
        "  dw = (x*db) - ((alpha/N)*w)\n",
        "  return dw.reshape((-1,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUFLNqL_GER9"
      },
      "source": [
        "<font color='red'>Grader function - 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WI3xD8ctGEnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b097d4ba-2b89-4182-b885-e65977816332"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "def grader_dw(x,y,w,b,alpha,N):\n",
        "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
        "  assert(np.round(np.sum(grad_dw),5)==4.75684)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w=np.array([ 0.03364887,  0.03612727,  0.02786927,  0.08547455, -0.12870234,\n",
        "       -0.02555288,  0.11858013,  0.13305576,  0.07310204,  0.15149245,\n",
        "       -0.05708987, -0.064768  ,  0.18012332, -0.16880843, -0.27079877])\n",
        "grad_b=0.5\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8g84_GI62n"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to 'b' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvTYZzZJJ_N"
      },
      "source": [
        "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0nUf2ft4EZp8"
      },
      "outputs": [],
      "source": [
        "#sb should be a scalar value\n",
        "def gradient_db(x,y,w,b):\n",
        "  w = w.reshape(w.shape+(1,))\n",
        "  x = x.reshape(x.shape+(1,))\n",
        "  w_t = np.transpose(w)\n",
        "  sigmoid_v  = sigmoid((np.matmul(w_t,x))+b)\n",
        "  db = y - sigmoid_v\n",
        "  return db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbcBzufVG6qk"
      },
      "source": [
        "<font color='red'>Grader function - 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TfFDKmscG5qZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9430f71-9141-4704-acbf-727aed0a08a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "def grader_db(x,y,w,b):\n",
        "  grad_db=gradient_db(x,y,w,b)\n",
        "  assert(np.round(grad_db,4)==-0.3714)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0.5\n",
        "grad_b=0.1\n",
        "grad_w=np.array([ 0.03364887,  0.03612727,  0.02786927,  0.08547455, -0.12870234,\n",
        "       -0.02555288,  0.11858013,  0.13305576,  0.07310204,  0.15149245,\n",
        "       -0.05708987, -0.064768  ,  0.18012332, -0.16880843, -0.27079877])\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_db(grad_x,grad_y,grad_w,grad_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wtNsfaBFpio2"
      },
      "outputs": [],
      "source": [
        "# prediction function used to compute predicted_y given the dataset X\n",
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        predict.append(sigmoid(z))\n",
        "    return np.array(predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCK0jY_EOvyU"
      },
      "source": [
        "<font color='blue'> Implementing logistic regression</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dmAdc5ejEZ25"
      },
      "outputs": [],
      "source": [
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0,N):\n",
        "  train_loss = []\n",
        "  test_loss = []\n",
        "  w,b = initialize_weights(X_train[0])\n",
        "\n",
        "  for e in range(epochs):\n",
        "    for data_p in range(0,len(X_train)):\n",
        "      dw=gradient_dw(X_train[data_p],y_train[data_p],w,b,alpha,N)\n",
        "      db=gradient_db(X_train[data_p],y_train[data_p],w,b)\n",
        "      w = w + (eta0*dw)\n",
        "      b = b + (eta0*db)\n",
        "    predicted_test = pred(w,b,X_test)\n",
        "    predicted_train = pred(w,b,X_train)\n",
        "    testloss = logloss(y_test,predicted_test)\n",
        "    trainloss = logloss(y_train,predicted_train)\n",
        "    train_loss.append(trainloss)\n",
        "    test_loss.append(testloss)\n",
        "  \n",
        "  return w,b,train_loss,test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sUquz7LFEZ6E"
      },
      "outputs": [],
      "source": [
        "alpha=0.001\n",
        "eta0=0.001\n",
        "N=len(X_train)\n",
        "epochs=20\n",
        "w,b,train_loss,test_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0,N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p6QQhs3wpio4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e981bc-8d03-444c-989b-bf0284bceb69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.41395277  0.19245295 -0.15005228  0.32635321 -0.22516684  0.58646736\n",
            " -0.42720457 -0.10028013  0.21483928  0.15555184  0.17881025 -0.01318754\n",
            " -0.06496902  0.36313889 -0.00985012]\n",
            "-0.9016735833888502\n"
          ]
        }
      ],
      "source": [
        "#print thr value of weights w and bias b\n",
        "print(w)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PZHyu26pio4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a16743a-b254-4b6d-8bbe-cf688f26ac9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.42336692, -0.18547565,  0.14859036, -0.34144407,  0.2081867 ,\n",
              "         -0.56016579,  0.45242483,  0.09408813, -0.2092732 , -0.18084126,\n",
              "         -0.19705191, -0.00421916,  0.0796037 , -0.33852802, -0.02266721]]),\n",
              " array([0.8531383]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "\n",
        "w-clf.coef_, b-clf.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X4s_U4NT54L",
        "outputId": "d0f9e36c-129d-4c1d-a486-764afa5bbbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.63664734, -0.94909336,  1.99834081, -4.12522514,  2.77723297,\n",
              "       -0.42874594, -0.97538552,  1.0936891 ,  2.78148657,  2.64325488,\n",
              "       -1.4050067 , -3.03278418,  5.18020963, -0.17992851, -2.2443886 ])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Zf_wPARlwY"
      },
      "source": [
        "## <font color='red'>Goal of assignment</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3eF_VSPSH2z"
      },
      "source": [
        "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in order of 10^-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkLz_cC9pio6"
      },
      "source": [
        "<font color='red'>Grader function - 6 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Sx1BCSRqpio6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552afaa0-1480-4189-f3d1-038aff13cc43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The custom weights are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#this grader function should return True\n",
        "#the difference between custom weights and clf.coef_ should be less than or equal to 0.05\n",
        "def differece_check_grader(w,b,coef,intercept):\n",
        "    val_array=np.abs(np.array(w-coef))\n",
        "    assert(np.all(val_array<=0.05))\n",
        "    print('The custom weights are correct')\n",
        "    return True\n",
        "differece_check_grader(w,b,clf.coef_,clf.intercept_)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230YbSgNSUrQ"
      },
      "source": [
        "<font color='blue'>Plot your train and test loss vs epochs </font>\n",
        "\n",
        "plot epoch number on X-axis and loss on Y-axis and make sure that the curve is converging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "epoch_array = list(range(0, 20))"
      ],
      "metadata": {
        "id": "FHO1pXUXbtln"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epoch_array,test_loss)\n",
        "plt.xlabel('Epochs', fontsize=15)\n",
        "plt.ylabel('Test Loss', fontsize=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "vFTbqcEyLR_1",
        "outputId": "8279820b-c91d-4fa6-abf2-6b040b98e76e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Test Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Custom_SGD_Assignment_LR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}