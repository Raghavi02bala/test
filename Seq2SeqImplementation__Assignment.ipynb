{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwPL0hIlGKoA"
      },
      "source": [
        "# <font color='red'>**Sequence to sequence implementation**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyfZo8fmLOec"
      },
      "source": [
        "## Task -1: Simple Encoder and Decoder\n",
        "Implement simple Encoder-Decoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XjOdQCvKJLC",
        "outputId": "f90137ae-01f1-4ba7-afb0-7b7399bd550f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEqXyzNmKJLE",
        "outputId": "2f0e662f-e8c2-4a7a-a3d6-36a505bd955f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.19.2'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k_AlAuKJqVA"
      },
      "source": [
        "<font color='blue'>**Load the data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU80Ao-AGaob",
        "outputId": "4f3efd75-aae7-4a8b-db88-ed80b0bd3dac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(353281, 2)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open('ita.txt','r', encoding=\"utf8\") as f:\n",
        "    eng=[]\n",
        "    ita=[]\n",
        "    for line in f:\n",
        "        eng.append(line.split('\\t')[0])\n",
        "        ita.append(line.split('\\t')[1])\n",
        "df = pd.DataFrame(data=list(zip(eng,ita)),columns=[\"English\",\"Italian\"])\n",
        "df.head()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmGWTdRmKRph"
      },
      "source": [
        "<font color='blue'>**Preprocess data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqKbMooJKJLG"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "def remove_tags(html):\n",
        "      soup = BeautifulSoup(html, \"html.parser\")\n",
        "    for data in soup(['style', 'script']):\n",
        "        data.decompose()\n",
        "      return ' '.join(soup.stripped_strings)\n",
        "\n",
        "def text_pp_eng(text):\n",
        "    txt = remove_tags(text)\n",
        "    \n",
        "    tokens = txt.split()\n",
        "    \n",
        "    for i,tok in enumerate(tokens):\n",
        "        tokens[i] = re.sub(r'[^http?\\:\\/\\/\\S*]','',tok)\n",
        "        tokens[i] = re.sub(r'[^https?\\:\\/\\/\\S*]','',tokens[i])\n",
        "        tokens[i] = re.sub(r'u200b', ' ', tokens[i])\n",
        "        tokens[i] = re.sub(r'u200', ' ', tokens[i])\n",
        "        tokens[i] = re.sub(r'xa0', ' ', tokens[i])\n",
        "        \n",
        "        tokens[i] = re.sub(r\"won\\'t\", \"will not\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"can\\'t\", \"can not\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"won\\’t\", \"will not\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"can\\’t\", \"can not\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"ain\\’t\", \"is not\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\’tis\", \"is\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"y\\’all\", \"you all\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"n\\'t\", \" not\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\'re\", \" are\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\'s\", \" is\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\'d\", \" would\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\'ll\", \" will\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\'t\", \" not\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\'ve\", \" have\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\'m\", \" am\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"n\\’t\", \" not\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\’re\", \" are\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\’s\", \" is\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\’d\", \" would\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\’ll\", \" will\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\’t\", \" not\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\’ve\", \" have\", tokens[i])\n",
        "        tokens[i] = re.sub(r\"\\’m\", \" am\", tokens[i])\n",
        "        \n",
        "        tokens[i] = re.sub(r'^()$', ' ', tokens[i])\n",
        "        tokens[i] = re.sub(r'^\\[\\]$', ' ', tokens[i])\n",
        "        tokens[i] = re.sub(r'^<>$', ' ', tokens[i])\n",
        "        tokens[i] = re.sub(r'^{}$', ' ', tokens[i])\n",
        "        \n",
        "        tokens[i] = re.sub('[^A-Za-z0-9\\s]','',tokens[i])\n",
        "            \n",
        "    tokens = [tok for tok in tokens if tok != '']\n",
        "    \n",
        "    for i,tok in enumerate(tokens):\n",
        "        tokens[i] = tok.lower()\n",
        "    \n",
        "    pptxt = ' '.join(tokens)\n",
        "    \n",
        "    return pptxt\n",
        "\n",
        "\n",
        "def text_pp_ita(text):\n",
        "    txt = remove_tags(text)    \n",
        "    tokens = txt.split()\n",
        "    for i,tok in enumerate(tokens):\n",
        "        tokens[i] = re.sub(r'http?\\:\\/\\/\\S*','',tok)\n",
        "        tokens[i] = re.sub(r'https?\\:\\/\\/\\S*','',tokens[i])\n",
        "        tokens[i] = re.sub(r'u200b', ' ', tokens[i])\n",
        "        tokens[i] = re.sub(r'u200', ' ', tokens[i])\n",
        "        tokens[i] = re.sub(r'xa0', ' ', tokens[i])\n",
        "        \n",
        "        tokens[i] = re.sub(r'^()$', ' ', tokens[i])\n",
        "        tokens[i] = re.sub(r'^\\[\\]$', ' ', tokens[i])\n",
        "        tokens[i] = re.sub(r'^<>$', ' ', tokens[i])\n",
        "        tokens[i] = re.sub(r'^{}$', ' ', tokens[i])\n",
        "        \n",
        "        tokens[i] = re.sub('[#$)\\?\"’.°!;\\'\\]\\[€%:,&@>\\-<=+(/_]','',tokens[i])\n",
        "            \n",
        "    tokens = [tok for tok in tokens if tok != '']\n",
        "    \n",
        "    for i,tok in enumerate(tokens):\n",
        "        tokens[i] = tok.lower()\n",
        "    pptxt = ' '.join(tokens)\n",
        "    return pptxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QqElB_nKZos",
        "outputId": "7eb21e93-8461-4a8c-fbd9-31ea5fe25b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Runtime 98.83728337287903 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "strt = time.time()\n",
        "df[\"English\"] = df[\"English\"].apply(text_pp_eng)\n",
        "df[\"Italian\"] = df[\"Italian\"].apply(text_pp_ita)\n",
        "end = time.time()\n",
        "print(\"Runtime\",end-strt,\"seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihdYKVA9KJLR"
      },
      "source": [
        "*CHECK FREQUENCY OF SENTENCES WITH RESPECT TO LENGTH OF SENTENCES*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIBVHYflKJLR"
      },
      "outputs": [],
      "source": [
        "ita_len = df['Italian'].str.split().apply(len)\n",
        "eng_len = df['English'].str.split().apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eFtGPoYKJLR",
        "outputId": "956f27cb-eb58-4980-8c50-b55dc12468f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90th percentile of italian sentence length 8.0\n",
            "91th percentile of italian sentence length 8.0\n",
            "92th percentile of italian sentence length 8.0\n",
            "93th percentile of italian sentence length 9.0\n",
            "94th percentile of italian sentence length 9.0\n",
            "95th percentile of italian sentence length 9.0\n",
            "96th percentile of italian sentence length 9.0\n",
            "97th percentile of italian sentence length 10.0\n",
            "98th percentile of italian sentence length 11.0\n",
            "99th percentile of italian sentence length 12.0\n",
            "100th percentile of italian sentence length 92.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(90,101):\n",
        "    print('{}th percentile of italian sentence length'.format(i),np.percentile(ita_len,i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbOpPN2NKJLR",
        "outputId": "cb1c77c5-9cb8-4c82-b5ab-dc3415c60b62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99.0th percentile of italian sentence length 12.0\n",
            "99.1th percentile of italian sentence length 12.0\n",
            "99.19999999999999th percentile of italian sentence length 12.0\n",
            "99.29999999999998th percentile of italian sentence length 13.0\n",
            "99.39999999999998th percentile of italian sentence length 13.0\n",
            "99.49999999999997th percentile of italian sentence length 13.0\n",
            "99.59999999999997th percentile of italian sentence length 14.0\n",
            "99.69999999999996th percentile of italian sentence length 15.0\n",
            "99.79999999999995th percentile of italian sentence length 16.0\n",
            "99.89999999999995th percentile of italian sentence length 22.0\n",
            "99.99th percentile of italian sentence length 44.0\n",
            "100th percentile of italian sentence length 92.0\n"
          ]
        }
      ],
      "source": [
        "for i in np.arange(99,100,0.1):\n",
        "    print('{}th percentile of italian sentence length'.format(i),np.percentile(ita_len,i))\n",
        "print('{}th percentile of italian sentence length'.format(99.99),np.percentile(ita_len,99.99))\n",
        "print('{}th percentile of italian sentence length'.format(100),np.percentile(ita_len,100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoJkwas4KJLS"
      },
      "source": [
        "**For italian text 99.89% of the texts are having length < 22**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4r3AGHbTKJLS",
        "outputId": "2b489aa6-11de-42b0-bfdb-8c32bd4cc8b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90th percentile of english sentence length 8.0\n",
            "91th percentile of english sentence length 9.0\n",
            "92th percentile of english sentence length 9.0\n",
            "93th percentile of english sentence length 9.0\n",
            "94th percentile of english sentence length 9.0\n",
            "95th percentile of english sentence length 9.0\n",
            "96th percentile of english sentence length 10.0\n",
            "97th percentile of english sentence length 10.0\n",
            "98th percentile of english sentence length 11.0\n",
            "99th percentile of english sentence length 12.0\n",
            "100th percentile of english sentence length 101.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(90,101):\n",
        "    print('{}th percentile of english sentence length'.format(i),np.percentile(eng_len,i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xbr9T7naKJLS",
        "outputId": "c06b9a65-aa5a-4b89-ce03-d0419c504333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99.0th percentile of english sentence length 12.0\n",
            "99.1th percentile of english sentence length 12.0\n",
            "99.19999999999999th percentile of english sentence length 13.0\n",
            "99.29999999999998th percentile of english sentence length 13.0\n",
            "99.39999999999998th percentile of english sentence length 13.0\n",
            "99.49999999999997th percentile of english sentence length 14.0\n",
            "99.59999999999997th percentile of english sentence length 14.0\n",
            "99.69999999999996th percentile of english sentence length 15.0\n",
            "99.79999999999995th percentile of english sentence length 16.0\n",
            "99.89999999999995th percentile of english sentence length 25.0\n",
            "99.99th percentile of english sentence length 41.0\n",
            "100th percentile of english sentence length 101.0\n"
          ]
        }
      ],
      "source": [
        "for i in np.arange(99,100,0.1):\n",
        "    print('{}th percentile of english sentence length'.format(i),np.percentile(eng_len,i))\n",
        "print('{}th percentile of english sentence length'.format(99.99),np.percentile(eng_len,99.99))\n",
        "print('{}th percentile of english sentence length'.format(100),np.percentile(eng_len,100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW1wWiN3KJLS"
      },
      "source": [
        "**For english text 99.89% of the texts are having length < 24**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5upSWaCKJLT"
      },
      "source": [
        "**So we will select texts of length < 24 for training our model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0I7lS9JKJLT"
      },
      "source": [
        "*TEACHER FORCING*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xTNqSjNKJLT",
        "outputId": "6e877a85-f71e-467b-a1fc-a149f26fff00"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Italian</th>\n",
              "      <th>eng_inp</th>\n",
              "      <th>eng_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;sos&gt; hi</td>\n",
              "      <td>hi &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;sos&gt; hi</td>\n",
              "      <td>hi &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>corri</td>\n",
              "      <td>&lt;sos&gt; run</td>\n",
              "      <td>run &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>corra</td>\n",
              "      <td>&lt;sos&gt; run</td>\n",
              "      <td>run &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>correte</td>\n",
              "      <td>&lt;sos&gt; run</td>\n",
              "      <td>run &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Italian    eng_inp    eng_out\n",
              "0     ciao   <sos> hi   hi <eos>\n",
              "1     ciao   <sos> hi   hi <eos>\n",
              "2    corri  <sos> run  run <eos>\n",
              "3    corra  <sos> run  run <eos>\n",
              "4  correte  <sos> run  run <eos>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"eng_len\"] = eng_len\n",
        "df[\"ita_len\"] = ita_len\n",
        "df = df[df[\"eng_len\"]<24]\n",
        "df = df[df[\"ita_len\"]<24]\n",
        "df[\"eng_inp\"] = '<sos> ' + df[\"English\"]\n",
        "df[\"eng_out\"] = df[\"English\"] + ' <eos>'\n",
        "df.drop(['eng_len','ita_len','English'],axis=1,inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gffcDU4MKJLT",
        "outputId": "66cf2ae9-a6f4-4c82-b886-0ab5a5c4cac3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(352885, 3)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPKKH4PkKJLT"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"df_preprocessed\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7lqWfVvKJLU",
        "outputId": "1470bcaa-2a00-421d-da00-6ba63d4fe52f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(282308, 3) (70577, 3)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtr,xval = train_test_split(df, test_size=0.2)\n",
        "print(xtr.shape, xval.shape)\n",
        "xtr.iloc[0]['eng_inp']= str(xtr.iloc[0]['eng_inp'])+' <eos>'\n",
        "xtr.iloc[0]['eng_out']= str(xtr.iloc[0]['eng_out'])+' <eos>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K1oAzO2KJLU"
      },
      "outputs": [],
      "source": [
        "tok_ita = Tokenizer()\n",
        "tok_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n') #removing <> from filters for <sos> and <eos>\n",
        "tok_ita.fit_on_texts(xtr[\"Italian\"].values)\n",
        "tok_eng.fit_on_texts(xtr[\"eng_inp\"].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVy2nR0_KJLV",
        "outputId": "25ce4d1d-b68d-490b-a1c0-87470cfa7f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of italian vocabulary: 26709\n",
            "========================================\n",
            "Length of english vocabulary: 13081\n"
          ]
        }
      ],
      "source": [
        "voc_size_ita = len(tok_ita.word_index.keys())\n",
        "print(\"Length of italian vocabulary:\", voc_size_ita)\n",
        "print(\"=\"*40)\n",
        "voc_size_eng = len(tok_eng.word_index.keys())\n",
        "print(\"Length of english vocabulary:\",voc_size_eng)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNcNacWLKJLV",
        "outputId": "5ef924bb-3a7d-46f1-b8cd-e605be0ed660"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 10336)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tok_eng.word_index['<sos>'], tok_eng.word_index['<eos>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBT24JGnKJLV",
        "outputId": "fb1dfd67-8f24-4518-c934-0a774d1be79f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13074, 100)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt',encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = vec\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((voc_size_eng+1, 100))\n",
        "for word, i in tok_eng.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzJSHt0DKJLV"
      },
      "outputs": [],
      "source": [
        "max_len_eng = max([len(txt.split()) for txt in df[\"eng_out\"].values])\n",
        "max_len_ita = max([len(txt.split()) for txt in df[\"Italian\"].values])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "## <font color='blue'>**Implement custom encoder decoder**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A45uc0JILMlV"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cex2XfCLOew"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.inp_voc_size = inp_vocab_size\n",
        "        self.emb_size = embedding_size\n",
        "        self.lstm_units = lstm_size\n",
        "        self.seq_len = input_length\n",
        "        self.emb_layer = Embedding(input_dim=self.inp_voc_size,output_dim=self.emb_size,mask_zero=True,\n",
        "                                   input_length=self.seq_len,name=\"enc_emb_layer\")\n",
        "        self.enc_lstm = LSTM(self.lstm_units,return_sequences=True,return_state=True,name=\"enc_lstm\")\n",
        "        self.lstm_out = 0\n",
        "        self.h_state = 0\n",
        "        self.c_state=0\n",
        "        \n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        emb_out = self.emb_layer(input_sequence)\n",
        "        self.lstm_out,self.h_state,self.c_state = self.enc_lstm(emb_out)\n",
        "        \n",
        "        return self.lstm_out,self.h_state,self.c_state\n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "        '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "        init_h_state = np.zeros((batch_size,self.lstm_units))\n",
        "        init_c_state = np.zeros((batch_size,self.lstm_units))\n",
        "      \n",
        "        return init_h_state,init_c_state\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtbOI3VwLOe0"
      },
      "source": [
        "<font color='orange'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziSqOgmhLOe1",
        "outputId": "c769c289-3465-4614-abab-553dc18f8a69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_check_encoder():\n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    #Intialzing encoder \n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    #Intializing encoder initial states\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    \n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1ES1-sJLOe4"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Decoder LSTM layer\n",
        "        self.out_voc_size = out_vocab_size\n",
        "        self.emb_size = embedding_size\n",
        "        self.lstm_units = lstm_size\n",
        "        self.seq_len = input_length\n",
        "        self.emb_layer = Embedding(input_dim=self.out_voc_size,output_dim=self.emb_size,mask_zero=True,\n",
        "                                   input_length=self.seq_len,name=\"dec_emb_layer\")\n",
        "        self.dec_lstm = LSTM(self.lstm_units,return_sequences=True,return_state=True,name=\"dec_lstm\")\n",
        "        self.lstm_out = 0\n",
        "        self.h_state = 0\n",
        "        self.c_state=0\n",
        "\n",
        "    def call(self,input_sequence,initial_states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
        "        \n",
        "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
        "        '''\n",
        "        emb_out = self.emb_layer(input_sequence)\n",
        "        self.lstm_out,self.h_state,self.c_state = self.dec_lstm(emb_out,initial_states)\n",
        "        \n",
        "        return self.lstm_out,self.h_state,self.c_state\n",
        "\n",
        "      \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-I0SUbLOe8"
      },
      "source": [
        "<font color='orange'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B0gokgKLOe8",
        "outputId": "6142619e-2448-480b-b4aa-2edfd87a86e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_decoder():\n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    states=[state_h,state_c]\n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
        "    output,_,_=decoder(target_sentences, states)\n",
        "    assert(output.shape==(batch_size,input_length,dec_units))\n",
        "    return True\n",
        "print(grader_decoder())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKDvQrwSKJLX"
      },
      "source": [
        "***DATA LOADER***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jub2kaFKJLX"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len_eng,max_len_ita):\n",
        "        self.encoder_inps = data['Italian'].values\n",
        "        self.decoder_inps = data['eng_inp'].values\n",
        "        self.decoder_outs = data['eng_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.max_len_eng = max_len_eng\n",
        "        self.max_len_ita = max_len_ita\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len_ita, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len_eng, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len_eng, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGaWutcVKJLY",
        "outputId": "3f36eda7-e5c0-4936-c665-851573b8bf3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 23) (64, 24) (64, 24)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Dataset(xtr, tok_ita, tok_eng, max_len_eng=max_len_eng,max_len_ita=max_len_ita)\n",
        "test_dataset  = Dataset(xval, tok_ita, tok_eng, max_len_eng=max_len_eng,max_len_ita=max_len_ita)\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=batch_size)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXrIj4scLOe_"
      },
      "outputs": [],
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,enc_voc_size,dec_voc_size,emb_size,lstm_units,seq_len_ita,seq_len_eng,batch_size,out_voc_size):\n",
        "        super().__init__()\n",
        "        self.batch_size=batch_size\n",
        "        #Create encoder object\n",
        "        self.encoder = Encoder(enc_voc_size,emb_size,lstm_units,seq_len_ita)\n",
        "        #Create decoder object\n",
        "        self.decoder = Decoder(dec_voc_size,emb_size,lstm_units,seq_len_eng)\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        self.dense_layer = Dense(out_voc_size,activation='softmax')\n",
        "    \n",
        "    \n",
        "    def call(self,data):\n",
        "        '''\n",
        "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
        "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
        "        C. Pass the decoder_outputs into Dense layer \n",
        "        \n",
        "        Return decoder_outputs\n",
        "        '''\n",
        "        inp,out = data[0],data[1]\n",
        "        enc_out,enc_h_state,enc_c_state = self.encoder(inp,states=self.encoder.initialize_states(self.batch_size))\n",
        "        dec_out,_,_ = self.decoder(input_sequence=out,initial_states=[enc_h_state,enc_c_state])\n",
        "        enc_dec_out = self.dense_layer(dec_out)\n",
        "        \n",
        "        return enc_dec_out\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcL61dJXLOfB"
      },
      "outputs": [],
      "source": [
        "#Create an object of encoder_decoder Model class, +\n",
        "enc_dec_model = Encoder_decoder(enc_voc_size=voc_size_ita+1,dec_voc_size=voc_size_eng+1,emb_size=100,lstm_units=64,\n",
        "                                seq_len_ita=max_len_ita,seq_len_eng=max_len_eng,batch_size=batch_size,out_voc_size=voc_size_eng+1)\n",
        "# Compile the model and fit the model\n",
        "enc_dec_model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "DT6HsnrFKJLZ",
        "outputId": "efe45784-e42c-4ed9-8541-c20be2793c02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "4411/4411 [==============================] - 118s 26ms/step - loss: 1.0870 - val_loss: 0.7909\n",
            "Epoch 2/20\n",
            "4411/4411 [==============================] - 112s 25ms/step - loss: 0.6698 - val_loss: 0.5819\n",
            "Epoch 3/20\n",
            "4411/4411 [==============================] - 112s 25ms/step - loss: 0.5017 - val_loss: 0.4667\n",
            "Epoch 4/20\n",
            "4411/4411 [==============================] - 112s 25ms/step - loss: 0.3984 - val_loss: 0.3953\n",
            "Epoch 5/20\n",
            "4411/4411 [==============================] - 113s 26ms/step - loss: 0.3300 - val_loss: 0.3485\n",
            "Epoch 6/20\n",
            "4411/4411 [==============================] - 113s 26ms/step - loss: 0.2816 - val_loss: 0.3168\n",
            "Epoch 7/20\n",
            "4411/4411 [==============================] - 112s 25ms/step - loss: 0.2459 - val_loss: 0.2937\n",
            "Epoch 8/20\n",
            "4411/4411 [==============================] - 112s 26ms/step - loss: 0.2188 - val_loss: 0.2773\n",
            "Epoch 9/20\n",
            "4411/4411 [==============================] - 112s 25ms/step - loss: 0.1975 - val_loss: 0.2645\n",
            "Epoch 10/20\n",
            "4411/4411 [==============================] - 112s 25ms/step - loss: 0.1802 - val_loss: 0.2561\n",
            "Epoch 11/20\n",
            "4411/4411 [==============================] - 113s 26ms/step - loss: 0.1661 - val_loss: 0.2482\n",
            "Epoch 12/20\n",
            "4411/4411 [==============================] - 113s 26ms/step - loss: 0.1540 - val_loss: 0.2417\n",
            "Epoch 13/20\n",
            "4411/4411 [==============================] - 113s 26ms/step - loss: 0.1438 - val_loss: 0.2366\n",
            "Epoch 14/20\n",
            "4411/4411 [==============================] - 112s 25ms/step - loss: 0.1349 - val_loss: 0.2340\n",
            "Epoch 15/20\n",
            "4411/4411 [==============================] - 112s 25ms/step - loss: 0.1274 - val_loss: 0.2302\n",
            "Epoch 16/20\n",
            "4411/4411 [==============================] - 113s 26ms/step - loss: 0.1205 - val_loss: 0.2289\n",
            "Epoch 17/20\n",
            "4411/4411 [==============================] - 113s 26ms/step - loss: 0.1145 - val_loss: 0.2267\n",
            "Epoch 18/20\n",
            "4411/4411 [==============================] - 113s 26ms/step - loss: 0.1091 - val_loss: 0.2246\n",
            "Epoch 19/20\n",
            "4411/4411 [==============================] - 112s 25ms/step - loss: 0.1043 - val_loss: 0.2238\n",
            "Epoch 20/20\n",
            "4411/4411 [==============================] - 112s 25ms/step - loss: 0.1000 - val_loss: 0.2243\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2d9f0cac5e0>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enc_dec_model.fit(train_dataloader,epochs=20,validation_data=test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEvZl7yZKJLZ",
        "outputId": "6045ea75-3cad-46d1-cdfb-5213a73a2d95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"encoder_decoder_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_2 (Encoder)          multiple                  2704140   \n",
            "_________________________________________________________________\n",
            "decoder_3 (Decoder)          multiple                  1350240   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  850200    \n",
            "=================================================================\n",
            "Total params: 4,904,580\n",
            "Trainable params: 4,904,580\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "enc_dec_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LxdPkLsKJLa",
        "outputId": "b2ebbeff-9ccd-44b5-d7d8-513cd35086fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<__main__.Encoder at 0x2d98649e400>,\n",
              " <__main__.Decoder at 0x2d9f080dfa0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x2d9e7e36dc0>]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enc_dec_model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkARSlZgLOfE"
      },
      "outputs": [],
      "source": [
        "def predict(input_sentence):\n",
        "    #A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    inp = tok_ita.texts_to_sequences([input_sentence])\n",
        "    inp = pad_sequences(inp, maxlen=max_len_ita, dtype='int32', padding='post')\n",
        "    print(inp.shape)\n",
        "    #B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    enc_out,enc_h_state,enc_c_state = enc_dec_model.layers[0](inp,enc_dec_model.encoder.initialize_states(batch_size=1))\n",
        "    #C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "    dec_inp = np.array(tok_eng.word_index['<sos>']).reshape(1,1)\n",
        "    #print(enc_out.shape,enc_h_state.shape,enc_c_state.shape,dec_inp.shape)\n",
        "    dec_stop = tok_eng.word_index['<eos>']\n",
        "    states=[enc_h_state,enc_c_state]\n",
        "    stop_condition=False\n",
        "    sent=''\n",
        "    k=0\n",
        "    while not stop_condition:\n",
        "        #D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "        predicted_out,state_h,state_c=enc_dec_model.layers[1](dec_inp,states)\n",
        "        #pass the predicted_out to the dense layer\n",
        "        pred_proba = enc_dec_model.layers[2](predicted_out)\n",
        "        #print(\"Shape of dense layer output:\",pred_proba.shape)\n",
        "    \n",
        "        #update the states=[state_h,state_c]\n",
        "        states=[state_h,state_c]\n",
        "        #And get the index of the word with maximum probability of the dense layer output, \n",
        "        #using the tokenizer(word index) get the word and then store it in a string.\n",
        "        word_ind = np.argmax(pred_proba,-1)\n",
        "        pred_str = list(tok_eng.word_index.keys())[int(word_ind-1)]\n",
        "        sent += ' '+pred_str\n",
        "        k+=1\n",
        "        if k>max_len_eng or int(word_ind) == int(dec_stop):\n",
        "            stop_condition=True\n",
        "        dec_inp = word_ind.reshape(1,1)\n",
        "    return sent,enc_out,state_h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foRhmLzFKJLa",
        "outputId": "c609c84a-07de-44ce-be2c-c8544bc62643"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('vidi un ufo', 'i saw a ufo <eos>')"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xval['Italian'].values[100],xval[\"eng_out\"].values[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njIBzIJiKJLb",
        "outputId": "29c81106-1c71-489c-8a90-2dc1779b1c1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 23)\n",
            "Translation time: 0.07 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' i saw a ufo <eos>'"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start = time.time()\n",
        "pred_sent,enc_output,dec_hid = predict(xval['Italian'].values[100])\n",
        "end = time.time()\n",
        "print(\"Translation time:\",round(end-start,2),\"seconds\")\n",
        "pred_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT6jB3UsKJLb",
        "outputId": "8edee527-e105-42fa-89bb-94ed2e111dcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "act = [xval[\"eng_out\"].values[2].split()]\n",
        "translated = pred_sent.split()\n",
        "bleu.sentence_bleu(act,translated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGRBClDhKJLb",
        "outputId": "2fdabfef-76a3-43a6-bc0a-2aa6b9fb5e74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' do not worry about it <eos>'"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"non ti preoccupare\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2IGIqt3KJLb",
        "outputId": "0eb4c21d-45a7-4fbd-d468-fdd081c8dc93"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Italian</th>\n",
              "      <th>eng_inp</th>\n",
              "      <th>eng_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>174060</th>\n",
              "      <td>sia tom che mary hanno riso</td>\n",
              "      <td>&lt;sos&gt; tom and mary both laughed</td>\n",
              "      <td>tom and mary both laughed &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284872</th>\n",
              "      <td>dovrebbe essere pronta al peggio</td>\n",
              "      <td>&lt;sos&gt; you should be ready for the worst</td>\n",
              "      <td>you should be ready for the worst &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226422</th>\n",
              "      <td>anche tu lo farai</td>\n",
              "      <td>&lt;sos&gt; are you going to do that too</td>\n",
              "      <td>are you going to do that too &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280951</th>\n",
              "      <td>non vuole parlarne</td>\n",
              "      <td>&lt;sos&gt; she does not want to talk about it</td>\n",
              "      <td>she does not want to talk about it &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52941</th>\n",
              "      <td>oggi offro io</td>\n",
              "      <td>&lt;sos&gt; today is my treat</td>\n",
              "      <td>today is my treat &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319103</th>\n",
              "      <td>hai mai mangiato del cibo turco prima</td>\n",
              "      <td>&lt;sos&gt; have you ever eaten turkish food before</td>\n",
              "      <td>have you ever eaten turkish food before &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279563</th>\n",
              "      <td>ero sposata quando avevo diciannove anni</td>\n",
              "      <td>&lt;sos&gt; i was married when i was nineteen</td>\n",
              "      <td>i was married when i was nineteen &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178120</th>\n",
              "      <td>perché avevi bisogno di un martello</td>\n",
              "      <td>&lt;sos&gt; why did you need a hammer</td>\n",
              "      <td>why did you need a hammer &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105040</th>\n",
              "      <td>so che qualcuno è qui</td>\n",
              "      <td>&lt;sos&gt; i know someone is here</td>\n",
              "      <td>i know someone is here &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146638</th>\n",
              "      <td>non vi dovete preoccupare</td>\n",
              "      <td>&lt;sos&gt; you do not need to worry</td>\n",
              "      <td>you do not need to worry &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Italian  \\\n",
              "174060               sia tom che mary hanno riso   \n",
              "284872          dovrebbe essere pronta al peggio   \n",
              "226422                         anche tu lo farai   \n",
              "280951                        non vuole parlarne   \n",
              "52941                              oggi offro io   \n",
              "...                                          ...   \n",
              "319103     hai mai mangiato del cibo turco prima   \n",
              "279563  ero sposata quando avevo diciannove anni   \n",
              "178120       perché avevi bisogno di un martello   \n",
              "105040                     so che qualcuno è qui   \n",
              "146638                 non vi dovete preoccupare   \n",
              "\n",
              "                                              eng_inp  \\\n",
              "174060                <sos> tom and mary both laughed   \n",
              "284872        <sos> you should be ready for the worst   \n",
              "226422             <sos> are you going to do that too   \n",
              "280951       <sos> she does not want to talk about it   \n",
              "52941                         <sos> today is my treat   \n",
              "...                                               ...   \n",
              "319103  <sos> have you ever eaten turkish food before   \n",
              "279563        <sos> i was married when i was nineteen   \n",
              "178120                <sos> why did you need a hammer   \n",
              "105040                   <sos> i know someone is here   \n",
              "146638                 <sos> you do not need to worry   \n",
              "\n",
              "                                              eng_out  \n",
              "174060                tom and mary both laughed <eos>  \n",
              "284872        you should be ready for the worst <eos>  \n",
              "226422             are you going to do that too <eos>  \n",
              "280951       she does not want to talk about it <eos>  \n",
              "52941                         today is my treat <eos>  \n",
              "...                                               ...  \n",
              "319103  have you ever eaten turkish food before <eos>  \n",
              "279563        i was married when i was nineteen <eos>  \n",
              "178120                why did you need a hammer <eos>  \n",
              "105040                   i know someone is here <eos>  \n",
              "146638                 you do not need to worry <eos>  \n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xval.sample(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "996pFO8BLOfG",
        "outputId": "356e133f-ea88-4cbd-8f27-d5ef739780e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU score of 1000 sample translations: 0.581992\n",
            "Translation time for 1000 sentences: 58.03 seconds\n"
          ]
        }
      ],
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "start = time.time()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sample = xval.sample(1000)\n",
        "predicted_sent=[]\n",
        "b_score = []\n",
        "for i,sent in enumerate(sample[\"Italian\"].values):\n",
        "    pred_sent = predict(sent)\n",
        "    predicted_sent.append(pred_sent)\n",
        "    bs = bleu.sentence_bleu([sample[\"eng_out\"].values[i].split()],pred_sent.split())\n",
        "    b_score.append(round(bs,3))\n",
        "sample[\"machine_translation\"] = predicted_sent\n",
        "sample[\"BLEU_score\"] = b_score\n",
        "sample.drop(\"eng_inp\",axis=1,inplace=True)\n",
        "\n",
        "print(\"Average BLEU score of 1000 sample translations:\",np.mean(b_score))\n",
        "    \n",
        "end = time.time()\n",
        "\n",
        "print(\"Translation time for 1000 sentences:\",round(end-start,2),\"seconds\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxWFDxZXLOfJ"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZhX3K9GLOfJ"
      },
      "source": [
        "## Task -2: Including Attention mechanisum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4KIsGxLOfK"
      },
      "source": [
        "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMm3ADQDLOfK"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx_5NA24KzRp"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.inp_voc_size = inp_vocab_size\n",
        "        self.emb_size = embedding_size\n",
        "        self.lstm_units = lstm_size\n",
        "        self.seq_len = input_length\n",
        "        self.emb_layer = Embedding(input_dim=self.inp_voc_size,output_dim=self.emb_size,mask_zero=True,\n",
        "                                   input_length=self.seq_len,name=\"enc_emb_layer\")\n",
        "        self.enc_lstm = LSTM(self.lstm_units,return_sequences=True,return_state=True,name=\"enc_lstm\")\n",
        "        self.lstm_out = 0\n",
        "        self.h_state = 0\n",
        "        self.c_state=0\n",
        "        \n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        emb_out = self.emb_layer(input_sequence)\n",
        "        self.lstm_out,self.h_state,self.c_state = self.enc_lstm(emb_out)\n",
        "        \n",
        "        return self.lstm_out,self.h_state,self.c_state\n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "        '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "        init_h_state = tf.zeros((batch_size,self.lstm_units))\n",
        "        init_c_state = tf.zeros((batch_size,self.lstm_units))\n",
        "      \n",
        "        return init_h_state,init_c_state\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ub9aN-hK244"
      },
      "source": [
        "<font color='cyan'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRoe65b9LB0D",
        "outputId": "8aa5dc9a-ca82-44b8-dcba-08769ebb6425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_check_encoder():\n",
        "    \n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units in encoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXn278lhLYRM"
      },
      "source": [
        "<font color='blue'>**Attention**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab5SNdPZLlur"
      },
      "outputs": [],
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self,scoring_function, att_units):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.scoring_function = scoring_function\n",
        "        self.att_units = att_units\n",
        "\n",
        "        if self.scoring_function=='dot':\n",
        "            pass\n",
        "            # Intialize variables needed for Dot score function here\n",
        "\n",
        "        elif scoring_function == 'general':\n",
        "          # Intialize variables needed for General score function here\n",
        "            self.wa = Dense(att_units)\n",
        "            \n",
        "        elif scoring_function == 'concat':\n",
        "            self.w1 = Dense(att_units)\n",
        "            self.w2 = Dense(att_units)\n",
        "            self.v = Dense(1)\n",
        "          # Intialize variables needed for Concat score function here\n",
        "            \n",
        "  \n",
        "  \n",
        "    def call(self,decoder_hidden_state,encoder_output):\n",
        "  \n",
        "    \n",
        "        if self.scoring_function == 'dot':\n",
        "            # Implement Dot score function here\n",
        "            state = tf.expand_dims(decoder_hidden_state,-1)\n",
        "            score = tf.matmul(encoder_output,state)\n",
        "            weights = tf.nn.softmax(score,axis=1)\n",
        "            weighted_out = encoder_output*weights\n",
        "            context_vec = tf.reduce_sum(weighted_out,axis=1)\n",
        "            \n",
        "            \"\"\"print(state.shape)\n",
        "            print(score.shape)\n",
        "            print(weights.shape)\n",
        "            print(weighted_out.shape)\n",
        "            print(context_vec.shape)\n",
        "            print(\"=\"*100)\"\"\"\n",
        "            \n",
        "            return context_vec,weights\n",
        "        \n",
        "        elif self.scoring_function == 'general':\n",
        "            # Implement General score function here\n",
        "            state = tf.expand_dims(decoder_hidden_state,2)\n",
        "            #print(state.shape)\n",
        "            score = tf.matmul(self.wa(encoder_output),state)\n",
        "            #print(\"score:\",score)\n",
        "            weights = tf.nn.softmax(score,axis=1)\n",
        "            weighted_out = encoder_output*weights\n",
        "            context_vec = tf.reduce_sum(weighted_out,axis=1)\n",
        "            \n",
        "            \"\"\"print(state.shape)\n",
        "            print(score.shape)\n",
        "            print(weights.shape)\n",
        "            print(weighted_out.shape)\n",
        "            print(context_vec.shape)\"\"\"\n",
        "            \n",
        "            return context_vec,weights\n",
        "           \n",
        "            \n",
        "        elif self.scoring_function == 'concat':\n",
        "            # Implement concat score function here\n",
        "            state = tf.expand_dims(decoder_hidden_state,1)\n",
        "            score = self.v(tf.nn.tanh(self.w1(state)+self.w2(encoder_output)))\n",
        "            #print(self.w1(state).shape,self.w2(encoder_output).shape)\n",
        "            #print(\"score:\",score.shape)\n",
        "            weights = tf.nn.softmax(score,axis=1)\n",
        "            #print(\"weights:\",weights.shape)\n",
        "            weighted_out = encoder_output*weights\n",
        "            context_vec = tf.reduce_sum(weighted_out,axis=1)\n",
        "            #print(\"context_vec:\",context_vec.shape)\n",
        "                \n",
        "            return context_vec,weights\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQDlxI9LuqK"
      },
      "source": [
        "<font color='cyan'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51x50h_TLrl9",
        "outputId": "cdc43de7-207a-4bbd-e07c-c22f1aa393c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_check_attention(scoring_fun):\n",
        "    \n",
        "    ''' \n",
        "        att_units: Used in matrix multiplications for scoring functions,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    att_units=32\n",
        "    \n",
        "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
        "    attention=Attention(scoring_fun,att_units)\n",
        "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
        "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
        "    return True\n",
        "print(grader_check_attention('dot'))\n",
        "print(grader_check_attention('general'))\n",
        "print(grader_check_attention('concat'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "<font color='blue'>**OneStepDecoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc8m7lmOL097"
      },
      "outputs": [],
      "source": [
        "class OneStepDecoder(tf.keras.Model):\n",
        "    def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "        super().__init__()\n",
        "        self.tar_voc_size = tar_vocab_size\n",
        "        self.embed_dim = embedding_dim\n",
        "        self.inp_len = input_length\n",
        "        self.dec_units = dec_units\n",
        "        self.score_fun = score_fun\n",
        "        self.att_units = att_units\n",
        "        \n",
        "        self.emb_layer = Embedding(self.tar_voc_size,self.embed_dim,input_length=self.inp_len)\n",
        "        self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True)\n",
        "        self.out_layer = Dense(self.tar_voc_size)\n",
        "        self.attention = Attention(self.score_fun, self.att_units)\n",
        "        \n",
        "        # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "        \n",
        "    def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "        emb = self.emb_layer(input_to_decoder)\n",
        "        context_vec,weights = self.attention(state_h,encoder_output)\n",
        "        concat = tf.concat([tf.expand_dims(context_vec,1),emb],axis=-1)\n",
        "        dec_output,dec_h_state,dec_c_state = self.lstm(concat, initial_state=[state_h, state_c])\n",
        "        rs_out = tf.reshape(dec_output,(-1,dec_output.shape[2]))\n",
        "        osd_out = self.out_layer(rs_out)\n",
        "        #print(emb.shape,context_vec.shape,concat.shape,dec_output.shape,rs_out.shape,osd_out.shape)\n",
        "        \n",
        "        return osd_out,dec_h_state,dec_c_state,weights,context_vec\n",
        "        \n",
        "    '''\n",
        "        One step decoder mechanisim step by step:\n",
        "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "      C. Concat the context vector with the step A output\n",
        "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "    '''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_I8I4EIMAXq"
      },
      "source": [
        "<font color='cyan'>**Grader function - 3**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLEXhChnMC1k",
        "outputId": "76f3a2a6-842e-4ce0-9ba9-727fd8933d0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_onestepdecoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        tar_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    tar_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    onestepdecoder=OneStepDecoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
        "    assert(output.shape==(batch_size,tar_vocab_size))\n",
        "    assert(state_h.shape==(batch_size,dec_units))\n",
        "    assert(state_c.shape==(batch_size,dec_units))\n",
        "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
        "    assert(context_vector.shape==(batch_size,dec_units))\n",
        "    return True\n",
        "    \n",
        "print(grader_onestepdecoder('dot'))\n",
        "print(grader_onestepdecoder('general'))\n",
        "print(grader_onestepdecoder('concat'))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "<font color='blue'>**Decoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV-x31rj6Hc4"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "        super().__init__()\n",
        "        self.out_voc_size = out_vocab_size\n",
        "        self.emb_dim = embedding_dim\n",
        "        self.inp_len = input_length\n",
        "        self.dec_units = dec_units\n",
        "        self.score_fun = score_fun\n",
        "        self.att_units = att_units\n",
        "        self.OSD = OneStepDecoder(self.out_voc_size, self.emb_dim, self.inp_len, self.dec_units, self.score_fun, self.att_units)\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "\n",
        "        \n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        #Create a tensor array as shown in the reference notebook\n",
        "        allstep_out = tf.TensorArray(tf.float32, size=tf.shape(input_to_decoder)[1], name=\"allstep_output\")\n",
        "        \n",
        "        for timestep in range(tf.shape(input_to_decoder)[1]):\n",
        "            osd_out,dec_h_state,dec_c_state,weights,context_vec=self.OSD(input_to_decoder[:,timestep:timestep+1], \n",
        "                                                                         encoder_output,decoder_hidden_state,decoder_cell_state)\n",
        "            allstep_out = allstep_out.write(timestep,osd_out)\n",
        "        allstep_out = tf.transpose(allstep_out.stack(), (1, 0, 2))\n",
        "        \n",
        "        return allstep_out\n",
        "        \n",
        "        #Iterate till the length of the decoder input\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            # Store the output in tensorarray\n",
        "        # Return the tensor array\n",
        "        \n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxrL-P8bMJH6"
      },
      "source": [
        "<font color='cyan'>**Grader function - 4**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtbx6onFMJXb",
        "outputId": "ed6b970e-59e4-4456-f077-36061ac2d2bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_decoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=11\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    \n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
        "    assert(output.shape==(batch_size,input_length,out_vocab_size))\n",
        "    return True\n",
        "print(grader_decoder('dot'))\n",
        "print(grader_decoder('general'))\n",
        "print(grader_decoder('concat'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "<font color='blue'>**Encoder Decoder model**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfqBIe20MT3D"
      },
      "outputs": [],
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "    def __init__(self,batch_size,inp_vocab_size,embedding_size,lstm_size,enc_input_length,\n",
        "                out_vocab_size, dec_input_length, dec_units ,score_fun ,att_units):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(inp_vocab_size, embedding_size, lstm_size, enc_input_length)\n",
        "        self.decoder = Decoder(out_vocab_size, embedding_size, dec_input_length, dec_units, score_fun, att_units)\n",
        "        \n",
        "            \n",
        "    def call(self,data):\n",
        "        #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "        input_sequence, input_to_decoder = data[0],data[1]\n",
        "        initial_state = self.encoder.initialize_states(batch_size)\n",
        "        encoder_output, state_h, state_c = self.encoder(input_sequence, initial_state)\n",
        "        \n",
        "        # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "        dec_h_state = state_h\n",
        "        dec_c_state = state_c\n",
        "        \n",
        "        # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "        decoder_output = self.decoder(input_to_decoder, encoder_output, dec_h_state, dec_c_state)\n",
        "        \n",
        "        # return the decoder output\n",
        "        return decoder_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "<font color='blue'>**Custom loss function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY_3izrXMs8y"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"dot_score_model.h5\", monitor='val_loss', \n",
        "                             verbose=1, save_weights_only = True, save_best_only=True, mode='auto',save_freq='epoch')\n",
        "\n",
        "%reload_ext tensorboard\n",
        "import datetime\n",
        "log_dir = \"log2/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "callbacks=[checkpoint,tensorboard_callback]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QlbWAqNNlqe"
      },
      "source": [
        "<font color='blue'>**Training**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtZUQF2NuZE"
      },
      "source": [
        "Implement dot function here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgyWwZWeMxGQ"
      },
      "outputs": [],
      "source": [
        "# Implement teacher forcing while training your model. You can do it two ways.\n",
        "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
        "# if decoder input is \n",
        "# <start> Hi how are you\n",
        "# decoder output should be\n",
        "# Hi How are you <end>\n",
        "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
        "\n",
        "# or\n",
        " \n",
        "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
        "# Note: If you follow this approach some grader functions might return false and this is fine.\n",
        "batch_size=64\n",
        "inp_vocab_size=voc_size_ita+1\n",
        "out_vocab_size=voc_size_eng+1\n",
        "embedding_size=100\n",
        "lstm_size=64\n",
        "enc_input_length=max_len_ita\n",
        "dec_input_length=max_len_eng\n",
        "dec_units=64\n",
        "score_fun='dot'\n",
        "att_units=64\n",
        "att_model = encoder_decoder(batch_size,inp_vocab_size,embedding_size,lstm_size,enc_input_length,\n",
        "                out_vocab_size, dec_input_length, dec_units ,score_fun ,att_units)\n",
        "att_model.compile(optimizer=optimizer,loss=loss_function)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "hO_YT6I2KJLh",
        "outputId": "b9305dac-1134-4607-d691-b63652aa5f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "4411/4411 [==============================] - 1365s 309ms/step - loss: 1.2782 - val_loss: 1.0380\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.03800, saving model to dot_score_model.h5\n",
            "Epoch 2/20\n",
            "4411/4411 [==============================] - 1362s 309ms/step - loss: 0.8988 - val_loss: 0.8012\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.03800 to 0.80115, saving model to dot_score_model.h5\n",
            "Epoch 3/20\n",
            "4411/4411 [==============================] - 1358s 308ms/step - loss: 0.7217 - val_loss: 0.6763\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.80115 to 0.67625, saving model to dot_score_model.h5\n",
            "Epoch 4/20\n",
            "4411/4411 [==============================] - 1355s 307ms/step - loss: 0.6035 - val_loss: 0.5859\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.67625 to 0.58594, saving model to dot_score_model.h5\n",
            "Epoch 5/20\n",
            "4411/4411 [==============================] - 1354s 307ms/step - loss: 0.5142 - val_loss: 0.5193\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.58594 to 0.51934, saving model to dot_score_model.h5\n",
            "Epoch 6/20\n",
            "4411/4411 [==============================] - 1355s 307ms/step - loss: 0.4470 - val_loss: 0.4718\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.51934 to 0.47184, saving model to dot_score_model.h5\n",
            "Epoch 7/20\n",
            "4411/4411 [==============================] - 1355s 307ms/step - loss: 0.3952 - val_loss: 0.4359\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.47184 to 0.43585, saving model to dot_score_model.h5\n",
            "Epoch 8/20\n",
            "4411/4411 [==============================] - 1355s 307ms/step - loss: 0.3547 - val_loss: 0.4093\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.43585 to 0.40933, saving model to dot_score_model.h5\n",
            "Epoch 9/20\n",
            "4411/4411 [==============================] - 1354s 307ms/step - loss: 0.3227 - val_loss: 0.3885\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.40933 to 0.38848, saving model to dot_score_model.h5\n",
            "Epoch 10/20\n",
            "4411/4411 [==============================] - 1356s 307ms/step - loss: 0.2968 - val_loss: 0.3728\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.38848 to 0.37281, saving model to dot_score_model.h5\n",
            "Epoch 11/20\n",
            "4411/4411 [==============================] - 1355s 307ms/step - loss: 0.2756 - val_loss: 0.3606\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.37281 to 0.36057, saving model to dot_score_model.h5\n",
            "Epoch 12/20\n",
            "4411/4411 [==============================] - 1353s 307ms/step - loss: 0.2577 - val_loss: 0.3506\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.36057 to 0.35060, saving model to dot_score_model.h5\n",
            "Epoch 13/20\n",
            "4411/4411 [==============================] - 1354s 307ms/step - loss: 0.2425 - val_loss: 0.3434\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.35060 to 0.34337, saving model to dot_score_model.h5\n",
            "Epoch 14/20\n",
            "4411/4411 [==============================] - 1354s 307ms/step - loss: 0.2296 - val_loss: 0.3376\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.34337 to 0.33759, saving model to dot_score_model.h5\n",
            "Epoch 15/20\n",
            "4411/4411 [==============================] - 1353s 307ms/step - loss: 0.2184 - val_loss: 0.3324\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.33759 to 0.33238, saving model to dot_score_model.h5\n",
            "Epoch 16/20\n",
            "4411/4411 [==============================] - 1354s 307ms/step - loss: 0.2085 - val_loss: 0.3295\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.33238 to 0.32955, saving model to dot_score_model.h5\n",
            "Epoch 17/20\n",
            "4411/4411 [==============================] - 1352s 307ms/step - loss: 0.1999 - val_loss: 0.3260\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.32955 to 0.32600, saving model to dot_score_model.h5\n",
            "Epoch 18/20\n",
            "4411/4411 [==============================] - 1352s 306ms/step - loss: 0.1923 - val_loss: 0.3246\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.32600 to 0.32464, saving model to dot_score_model.h5\n",
            "Epoch 19/20\n",
            "4411/4411 [==============================] - 1353s 307ms/step - loss: 0.1857 - val_loss: 0.3226\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.32464 to 0.32259, saving model to dot_score_model.h5\n",
            "Epoch 20/20\n",
            "4411/4411 [==============================] - 1351s 306ms/step - loss: 0.1796 - val_loss: 0.3215\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.32259 to 0.32153, saving model to dot_score_model.h5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1de2edd5be0>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "att_model.fit(train_dataloader,epochs=20,callbacks=callbacks,validation_data=test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DpC9zlzMcXp"
      },
      "source": [
        "## <font color='blue'>**Inference**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5NhESYyMW_t"
      },
      "source": [
        "<font color='blue'>**Plot attention weights**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkEY7SsBMtrC"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    sentence = sentence.split()\n",
        "    sentence = ['<sos>'] + sentence + ['<eos>']\n",
        "    predicted_sentence =predicted_sentence.split()+ ['<eos>']\n",
        "    \n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    \n",
        "    attention = attention[:len(predicted_sentence), :len(sentence)]\n",
        "\n",
        "    ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
        "\n",
        "    ax.set_xlabel('Input text')\n",
        "    ax.set_ylabel('Output text')\n",
        "    plt.suptitle('Attention weights')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apnpkNuKKJLi",
        "outputId": "e4b65f23-fa3e-47fd-fc58-904d50ffc189"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tom', 'non', 'lha', 'fatto']"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xval['Italian'].values[80].split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1IhdBrgQYJr"
      },
      "source": [
        "<font color='blue'>**Predict the sentence translation**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP3kLZoPMvSu"
      },
      "outputs": [],
      "source": [
        "def predict(input_sentence):\n",
        "    #A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    inp = tok_ita.texts_to_sequences([input_sentence])\n",
        "    inp = pad_sequences(inp, maxlen=max_len_ita, dtype='int32', padding='post')\n",
        "    #print(\"input_shape\",inp.shape)\n",
        "    #B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    enc_out,enc_h_state,enc_c_state = att_model.layers[0](inp,att_model.encoder.initialize_states(batch_size=1))\n",
        "    #C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "    dec_inp = np.array(tok_eng.word_index['<sos>']).reshape(1,1)\n",
        "    #print(enc_out.shape,enc_h_state.shape,enc_c_state.shape,dec_inp.shape)\n",
        "    dec_stop = tok_eng.word_index['<eos>']\n",
        "    states=[enc_h_state,enc_c_state]\n",
        "    stop_condition=False\n",
        "    sent=''\n",
        "    k=0\n",
        "    output_len = max_len_eng\n",
        "    input_len = max_len_ita\n",
        "    attention_weights_list = []\n",
        "    #print(\"att_plot shape:\",attention_plot.shape)\n",
        "    \n",
        "    for t in range(output_len):\n",
        "        predictions,state_h,state_c,attention_weights,context_vector = att_model.layers[1].OSD(dec_inp,\n",
        "                                                                                                      enc_out,\n",
        "                                                                                                      enc_h_state,enc_c_state)\n",
        "        #print(\"OSD pred shape:\",predictions.shape)\n",
        "        attention_weights_list.append(attention_weights[0,:,0])\n",
        "        \n",
        "        word_ind = np.argmax(predictions,-1)\n",
        "        \n",
        "        pred_str = list(tok_eng.word_index.keys())[int(word_ind-1)]\n",
        "        \n",
        "        sent += ' '+pred_str\n",
        "        k+=1\n",
        "        if k>max_len_eng or int(word_ind) == int(dec_stop):\n",
        "            return sent,attention_plot\n",
        "        \n",
        "        dec_inp = word_ind.reshape(1,1)\n",
        "        \n",
        "    return sent, np.array(attention_weights_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mZVDqmtKJLi"
      },
      "source": [
        "**SAMPLE TRANSLATION AND ATTENTION PLOT USING TRAINED MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbLm3_0UKJLi",
        "outputId": "b4a95f31-e97a-4f7f-8473-da570efcfe6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Italian    lasciate che lo dica a tom\n",
              "eng_inp         <sos> let me tell tom\n",
              "eng_out         let me tell tom <eos>\n",
              "Name: 28961, dtype: object"
            ]
          },
          "execution_count": 283,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xval.iloc[150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rZS05qSKJLj",
        "outputId": "2e0aa120-0db0-43bd-be45-2815ac3b70e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Italian sentence:   lasciate che lo dica a tom\n",
            "Translated sentence:    let me tell tom <eos>\n",
            "Translation time: 0.05 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"Italian sentence:  \",xval['Italian'].values[150])\n",
        "start = time.time()\n",
        "pred_sent,attention_plot = predict(xval['Italian'].values[150])\n",
        "end = time.time()\n",
        "print(\"Translated sentence:  \",pred_sent)\n",
        "print(\"Translation time:\",round(end-start,2),\"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSVgqPaOKJLj",
        "outputId": "12fe58a8-4a2f-4095-fff4-c79a54701da3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-292-7524cf7920bc>:16: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "<ipython-input-292-7524cf7920bc>:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_attention(attention_plot, xval['Italian'].values[150], pred_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIinP3TEKJLj",
        "outputId": "e72b070d-d172-4b6b-8e19-37208a148f75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Italian               tom in realtà non vive a boston\n",
              "eng_inp    <sos> tom does not actually live in boston\n",
              "eng_out    tom does not actually live in boston <eos>\n",
              "Name: 298899, dtype: object"
            ]
          },
          "execution_count": 321,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xval.iloc[235]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HamBes9rKJLj",
        "outputId": "3d4b339a-77ce-4e4c-bafe-b4141bf1d1e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Italian sentence:   tom in realtà non vive a boston\n",
            "Translated sentence:    tom does not actually live in boston <eos>\n",
            "Translation time: 0.1 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"Italian sentence:  \",xval['Italian'].values[235])\n",
        "start = time.time()\n",
        "pred_sent,attention_plot = predict(xval['Italian'].values[235])\n",
        "end = time.time()\n",
        "print(\"Translated sentence:  \",pred_sent)\n",
        "print(\"Translation time:\",round(end-start,2),\"seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxIVOOQPWMu"
      },
      "source": [
        "<font color='blue'>**Calculate BLEU score**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc63xgu2KJLj",
        "outputId": "955c7a4f-2651-4ac8-fcde-9f084b81ecaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU score of 1000 sample translations: 0.40623699999999996\n",
            "Translation time for 1000 sentences: 58.37 seconds\n"
          ]
        }
      ],
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sample = xval.sample(1000)\n",
        "predicted_sent=[]\n",
        "b_score = []\n",
        "for i,sent in enumerate(sample[\"Italian\"].values):\n",
        "    pred_sent,attention_plot = predict(sent)\n",
        "    predicted_sent.append(pred_sent)\n",
        "    bs = bleu.sentence_bleu([sample[\"eng_out\"].values[i].split()],pred_sent.split())\n",
        "    b_score.append(round(bs,3))\n",
        "sample[\"machine_translation\"] = predicted_sent\n",
        "sample[\"BLEU_score\"] = b_score\n",
        "sample.drop(\"eng_inp\",axis=1,inplace=True)\n",
        "\n",
        "print(\"Average BLEU score of 1000 sample translations:\",np.mean(b_score))\n",
        "    \n",
        "end = time.time()\n",
        "\n",
        "print(\"Translation time for 1000 sentences:\",round(end-start,2),\"seconds\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "C0iLdEQoKJLk",
        "outputId": "b2962782-04ce-4ea8-82b3-dc4f0ecad441"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Italian</th>\n",
              "      <th>eng_out</th>\n",
              "      <th>machine_translation</th>\n",
              "      <th>BLEU_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>135819</th>\n",
              "      <td>io ho molti rimpianti</td>\n",
              "      <td>i have a lot of regrets &lt;eos&gt;</td>\n",
              "      <td>i have a lot of regrets &lt;eos&gt;</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327756</th>\n",
              "      <td>io ho molte cose da fare stamattina</td>\n",
              "      <td>i have a lot of things to do this morning &lt;eos&gt;</td>\n",
              "      <td>i have many things to do this kind of doing t...</td>\n",
              "      <td>0.122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180206</th>\n",
              "      <td>voi avete molto denaro</td>\n",
              "      <td>do you have a lot of money &lt;eos&gt;</td>\n",
              "      <td>do you have a lot of money &lt;eos&gt;</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312570</th>\n",
              "      <td>tom cominciò a lavorare a boston nel 2013</td>\n",
              "      <td>tom started working in boston in 2013 &lt;eos&gt;</td>\n",
              "      <td>tom started working in 2013 &lt;eos&gt;</td>\n",
              "      <td>0.507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80007</th>\n",
              "      <td>hanno bisogno del vostro aiuto</td>\n",
              "      <td>they need your help &lt;eos&gt;</td>\n",
              "      <td>they need your help &lt;eos&gt;</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106310</th>\n",
              "      <td>mi è stato detto di entrare</td>\n",
              "      <td>i was told to come in &lt;eos&gt;</td>\n",
              "      <td>i was too &lt;eos&gt;</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297181</th>\n",
              "      <td>se non ti dispiace andrò con tom</td>\n",
              "      <td>if you do not mind i will go with tom &lt;eos&gt;</td>\n",
              "      <td>if you do not go i will not go i will not go ...</td>\n",
              "      <td>0.122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304902</th>\n",
              "      <td>non succederà questa volta</td>\n",
              "      <td>that is not going to happen this time &lt;eos&gt;</td>\n",
              "      <td>it is not happen this is not happen this is n...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265414</th>\n",
              "      <td>state dicendo che è sbagliato</td>\n",
              "      <td>are you saying that that is wrong &lt;eos&gt;</td>\n",
              "      <td>are you saying that is wrong &lt;eos&gt;</td>\n",
              "      <td>0.689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21792</th>\n",
              "      <td>sono felici</td>\n",
              "      <td>they are happy &lt;eos&gt;</td>\n",
              "      <td>they are happy &lt;eos&gt;</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334157</th>\n",
              "      <td>cè qualcuno che riesce a pronunciare questa pa...</td>\n",
              "      <td>is there anyone who can pronounce this word &lt;eos&gt;</td>\n",
              "      <td>is this word &lt;eos&gt;</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187763</th>\n",
              "      <td>può avermi detto una menzogna</td>\n",
              "      <td>she may have told me a lie &lt;eos&gt;</td>\n",
              "      <td>could lie &lt;eos&gt;</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311717</th>\n",
              "      <td>io e tom ci conosciamo a vicenda molto bene</td>\n",
              "      <td>tom and i know each other fairly well &lt;eos&gt;</td>\n",
              "      <td>tom and i see each other guys i see each othe...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197535</th>\n",
              "      <td>tutti guardavano tom</td>\n",
              "      <td>everyone looked over at tom &lt;eos&gt;</td>\n",
              "      <td>everyone looked at tom &lt;eos&gt;</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137089</th>\n",
              "      <td>penso che noi eravamo fantastiche</td>\n",
              "      <td>i think we were awesome &lt;eos&gt;</td>\n",
              "      <td>i think we were awesome &lt;eos&gt;</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311146</th>\n",
              "      <td>mi dica tutto quello che sa su di tom</td>\n",
              "      <td>tell me everything you know about tom &lt;eos&gt;</td>\n",
              "      <td>tell me to tell me to tell me to tell me to t...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126872</th>\n",
              "      <td>tom è dispotico vero</td>\n",
              "      <td>tom is bossy is not he &lt;eos&gt;</td>\n",
              "      <td>tom is bossy is bossy is bossy is bossy is bo...</td>\n",
              "      <td>0.098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266443</th>\n",
              "      <td>ha mai imbrogliato a un esame</td>\n",
              "      <td>have you ever cheated on an exam &lt;eos&gt;</td>\n",
              "      <td>have an exam &lt;eos&gt;</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193009</th>\n",
              "      <td>beh rivoglio indietro il mio denaro</td>\n",
              "      <td>well i want my money back &lt;eos&gt;</td>\n",
              "      <td>well i want my money back &lt;eos&gt;</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93262</th>\n",
              "      <td>posso prendere un messaggio</td>\n",
              "      <td>may i take a message &lt;eos&gt;</td>\n",
              "      <td>can i take a message &lt;eos&gt;</td>\n",
              "      <td>0.760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Italian  \\\n",
              "135819                              io ho molti rimpianti   \n",
              "327756                io ho molte cose da fare stamattina   \n",
              "180206                             voi avete molto denaro   \n",
              "312570          tom cominciò a lavorare a boston nel 2013   \n",
              "80007                      hanno bisogno del vostro aiuto   \n",
              "106310                        mi è stato detto di entrare   \n",
              "297181                   se non ti dispiace andrò con tom   \n",
              "304902                         non succederà questa volta   \n",
              "265414                      state dicendo che è sbagliato   \n",
              "21792                                         sono felici   \n",
              "334157  cè qualcuno che riesce a pronunciare questa pa...   \n",
              "187763                      può avermi detto una menzogna   \n",
              "311717        io e tom ci conosciamo a vicenda molto bene   \n",
              "197535                               tutti guardavano tom   \n",
              "137089                  penso che noi eravamo fantastiche   \n",
              "311146              mi dica tutto quello che sa su di tom   \n",
              "126872                               tom è dispotico vero   \n",
              "266443                      ha mai imbrogliato a un esame   \n",
              "193009                beh rivoglio indietro il mio denaro   \n",
              "93262                         posso prendere un messaggio   \n",
              "\n",
              "                                                  eng_out  \\\n",
              "135819                      i have a lot of regrets <eos>   \n",
              "327756    i have a lot of things to do this morning <eos>   \n",
              "180206                   do you have a lot of money <eos>   \n",
              "312570        tom started working in boston in 2013 <eos>   \n",
              "80007                           they need your help <eos>   \n",
              "106310                        i was told to come in <eos>   \n",
              "297181        if you do not mind i will go with tom <eos>   \n",
              "304902        that is not going to happen this time <eos>   \n",
              "265414            are you saying that that is wrong <eos>   \n",
              "21792                                they are happy <eos>   \n",
              "334157  is there anyone who can pronounce this word <eos>   \n",
              "187763                   she may have told me a lie <eos>   \n",
              "311717        tom and i know each other fairly well <eos>   \n",
              "197535                  everyone looked over at tom <eos>   \n",
              "137089                      i think we were awesome <eos>   \n",
              "311146        tell me everything you know about tom <eos>   \n",
              "126872                       tom is bossy is not he <eos>   \n",
              "266443             have you ever cheated on an exam <eos>   \n",
              "193009                    well i want my money back <eos>   \n",
              "93262                          may i take a message <eos>   \n",
              "\n",
              "                                      machine_translation  BLEU_score  \n",
              "135819                      i have a lot of regrets <eos>       1.000  \n",
              "327756   i have many things to do this kind of doing t...       0.122  \n",
              "180206                   do you have a lot of money <eos>       1.000  \n",
              "312570                  tom started working in 2013 <eos>       0.507  \n",
              "80007                           they need your help <eos>       1.000  \n",
              "106310                                    i was too <eos>       0.000  \n",
              "297181   if you do not go i will not go i will not go ...       0.122  \n",
              "304902   it is not happen this is not happen this is n...       0.000  \n",
              "265414                 are you saying that is wrong <eos>       0.689  \n",
              "21792                                they are happy <eos>       1.000  \n",
              "334157                                 is this word <eos>       0.000  \n",
              "187763                                    could lie <eos>       0.000  \n",
              "311717   tom and i see each other guys i see each othe...       0.000  \n",
              "197535                       everyone looked at tom <eos>       0.000  \n",
              "137089                      i think we were awesome <eos>       1.000  \n",
              "311146   tell me to tell me to tell me to tell me to t...       0.000  \n",
              "126872   tom is bossy is bossy is bossy is bossy is bo...       0.098  \n",
              "266443                                 have an exam <eos>       0.000  \n",
              "193009                    well i want my money back <eos>       1.000  \n",
              "93262                          can i take a message <eos>       0.760  "
            ]
          },
          "execution_count": 296,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWg2ferDQvT3"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU2pH8XmKJLk"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"concat_score_model.h5\", monitor='val_loss', \n",
        "                             verbose=1, save_weights_only = True, save_best_only=True, mode='auto',save_freq='epoch')\n",
        "\n",
        "%reload_ext tensorboard\n",
        "import datetime\n",
        "log_dir = \"log3/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "callbacks=[checkpoint,tensorboard_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Rh9_w79M5JO"
      },
      "outputs": [],
      "source": [
        "#Compile and train your model on general scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "batch_size=64\n",
        "inp_vocab_size=voc_size_ita+1\n",
        "out_vocab_size=voc_size_eng+1\n",
        "embedding_size=100\n",
        "lstm_size=64\n",
        "enc_input_length=max_len_ita\n",
        "dec_input_length=max_len_eng\n",
        "dec_units=64\n",
        "score_fun='concat'\n",
        "att_units=64\n",
        "att_model_conc = encoder_decoder(batch_size,inp_vocab_size,embedding_size,lstm_size,enc_input_length,\n",
        "                out_vocab_size, dec_input_length, dec_units ,score_fun ,att_units)\n",
        "att_model_conc.compile(optimizer=optimizer,loss=loss_function)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "PYmt7cr0KJLk",
        "outputId": "6b14b262-1ac9-4b6f-b42c-b119381c0a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "4411/4411 [==============================] - 1818s 411ms/step - loss: 1.2861 - val_loss: 1.1802\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.18024, saving model to concat_score_model.h5\n",
            "Epoch 2/20\n",
            "4411/4411 [==============================] - 2258s 512ms/step - loss: 0.8890 - val_loss: 0.9595\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.18024 to 0.95950, saving model to concat_score_model.h5\n",
            "Epoch 3/20\n",
            "4411/4411 [==============================] - 1784s 404ms/step - loss: 0.6895 - val_loss: 0.8704\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.95950 to 0.87037, saving model to concat_score_model.h5\n",
            "Epoch 4/20\n",
            "4411/4411 [==============================] - 1795s 407ms/step - loss: 0.5594 - val_loss: 0.8224\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.87037 to 0.82237, saving model to concat_score_model.h5\n",
            "Epoch 5/20\n",
            "4411/4411 [==============================] - 1795s 407ms/step - loss: 0.4705 - val_loss: 0.8317\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.82237\n",
            "Epoch 6/20\n",
            "4411/4411 [==============================] - 1773s 402ms/step - loss: 0.4075 - val_loss: 0.8083\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.82237 to 0.80831, saving model to concat_score_model.h5\n",
            "Epoch 7/20\n",
            "4411/4411 [==============================] - 1834s 416ms/step - loss: 0.3611 - val_loss: 0.8023\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.80831 to 0.80233, saving model to concat_score_model.h5\n",
            "Epoch 8/20\n",
            "4411/4411 [==============================] - 1797s 407ms/step - loss: 0.3252 - val_loss: 0.7684\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.80233 to 0.76838, saving model to concat_score_model.h5\n",
            "Epoch 9/20\n",
            "4411/4411 [==============================] - 1788s 405ms/step - loss: 0.2968 - val_loss: 0.7580\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.76838 to 0.75798, saving model to concat_score_model.h5\n",
            "Epoch 10/20\n",
            "4411/4411 [==============================] - 1818s 412ms/step - loss: 0.2734 - val_loss: 0.8099\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.75798\n",
            "Epoch 11/20\n",
            "4411/4411 [==============================] - 1827s 414ms/step - loss: 0.2544 - val_loss: 0.7594\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.75798\n",
            "Epoch 12/20\n",
            "4411/4411 [==============================] - 1807s 410ms/step - loss: 0.2382 - val_loss: 0.7666\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.75798\n",
            "Epoch 13/20\n",
            "4411/4411 [==============================] - 1783s 404ms/step - loss: 0.2245 - val_loss: 0.7668\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.75798\n",
            "Epoch 14/20\n",
            "4411/4411 [==============================] - 1796s 407ms/step - loss: 0.2126 - val_loss: 0.7570\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.75798 to 0.75703, saving model to concat_score_model.h5\n",
            "Epoch 15/20\n",
            "4411/4411 [==============================] - 1789s 406ms/step - loss: 0.2023 - val_loss: 0.7609\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.75703\n",
            "Epoch 16/20\n",
            "4411/4411 [==============================] - 1791s 406ms/step - loss: 0.1933 - val_loss: 0.7415\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.75703 to 0.74154, saving model to concat_score_model.h5\n",
            "Epoch 17/20\n",
            "4411/4411 [==============================] - 1792s 406ms/step - loss: 0.1852 - val_loss: 0.7207\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.74154 to 0.72066, saving model to concat_score_model.h5\n",
            "Epoch 18/20\n",
            "4411/4411 [==============================] - 1796s 407ms/step - loss: 0.1781 - val_loss: 0.7175\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.72066 to 0.71753, saving model to concat_score_model.h5\n",
            "Epoch 19/20\n",
            "4411/4411 [==============================] - 1793s 407ms/step - loss: 0.1718 - val_loss: 0.7452\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.71753\n",
            "Epoch 20/20\n",
            "4411/4411 [==============================] - 1785s 405ms/step - loss: 0.1660 - val_loss: 0.7146\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.71753 to 0.71456, saving model to concat_score_model.h5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1df6d44b8e0>"
            ]
          },
          "execution_count": 312,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "att_model_conc.fit(train_dataloader,epochs=20,callbacks=callbacks,validation_data=test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WshSOXntKJLl"
      },
      "outputs": [],
      "source": [
        "def predict_conc(input_sentence):\n",
        "    #A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    inp = tok_ita.texts_to_sequences([input_sentence])\n",
        "    inp = pad_sequences(inp, maxlen=max_len_ita, dtype='int32', padding='post')\n",
        "    #print(\"input_shape\",inp.shape)\n",
        "    #B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    enc_out,enc_h_state,enc_c_state = att_model_conc.layers[0](inp,att_model.encoder.initialize_states(batch_size=1))\n",
        "    #C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "    dec_inp = np.array(tok_eng.word_index['<sos>']).reshape(1,1)\n",
        "    #print(enc_out.shape,enc_h_state.shape,enc_c_state.shape,dec_inp.shape)\n",
        "    dec_stop = tok_eng.word_index['<eos>']\n",
        "    states=[enc_h_state,enc_c_state]\n",
        "    stop_condition=False\n",
        "    sent=''\n",
        "    k=0\n",
        "    output_len = max_len_eng\n",
        "    input_len = max_len_ita\n",
        "    attention_weights_list = []\n",
        "    #print(\"att_plot shape:\",attention_plot.shape)\n",
        "    \n",
        "    for t in range(output_len):\n",
        "        predictions,state_h,state_c,attention_weights,context_vector = att_model_conc.layers[1].OSD(dec_inp,\n",
        "                                                                                                      enc_out,\n",
        "                                                                                                      enc_h_state,enc_c_state)\n",
        "        #print(\"OSD pred shape:\",predictions.shape)\n",
        "        attention_weights_list.append(attention_weights[0,:,0])\n",
        "        \n",
        "        word_ind = np.argmax(predictions,-1)\n",
        "        \n",
        "        pred_str = list(tok_eng.word_index.keys())[int(word_ind-1)]\n",
        "        \n",
        "        sent += ' '+pred_str\n",
        "        k+=1\n",
        "        if k>max_len_eng or int(word_ind) == int(dec_stop):\n",
        "            return sent,np.array(attention_weights_list)\n",
        "        \n",
        "        dec_inp = word_ind.reshape(1,1)\n",
        "        \n",
        "    return sent, np.array(attention_weights_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86LS-C-BKJLl",
        "outputId": "790ae30c-3d8f-4696-8728-10593fc8c27e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Italian    lasciate che lo dica a tom\n",
              "eng_inp         <sos> let me tell tom\n",
              "eng_out         let me tell tom <eos>\n",
              "Name: 28961, dtype: object"
            ]
          },
          "execution_count": 316,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xval.iloc[150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll7MNntiKJLl",
        "outputId": "ef1c9e17-775a-4273-d377-e4d7502b114f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Italian sentence:   lasciate che lo dica a tom\n",
            "Translated sentence:    if tom <eos>\n",
            "Translation time: 13.57 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"Italian sentence:  \",xval['Italian'].values[150])\n",
        "start = time.time()\n",
        "pred_sent,attention_plot = predict_conc(xval['Italian'].values[150])\n",
        "end = time.time()\n",
        "print(\"Translated sentence:  \",pred_sent)\n",
        "print(\"Translation time:\",round(end-start,2),\"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7aaNInIKJLl",
        "outputId": "6a9b7c5b-c2fe-4c22-c529-4dda33a72fb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Italian               tom in realtà non vive a boston\n",
              "eng_inp    <sos> tom does not actually live in boston\n",
              "eng_out    tom does not actually live in boston <eos>\n",
              "Name: 298899, dtype: object"
            ]
          },
          "execution_count": 318,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xval.iloc[235]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsR-04UzKJLl",
        "outputId": "f2568d4d-3030-4e1d-9c1d-f6f19ef31168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Italian sentence:   tom in realtà non vive a boston\n",
            "Translated sentence:    he still get still get still get still get still get still get still get still get still get still get still get still\n",
            "Translation time: 0.23 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"Italian sentence:  \",xval['Italian'].values[235])\n",
        "start = time.time()\n",
        "pred_sent,attention_plot = predict_conc(xval['Italian'].values[235])\n",
        "end = time.time()\n",
        "print(\"Translated sentence:  \",pred_sent)\n",
        "print(\"Translation time:\",round(end-start,2),\"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3znayKysKJLm",
        "outputId": "a762a700-4cc1-465b-d6fd-bacf86bac1cd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_attention(attention_plot, xval['Italian'].values[150], pred_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eYVCLBIKJLm",
        "outputId": "758cf950-0b9f-4614-a067-2e8712dc57ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU score of 1000 sample translations: 0.110006\n",
            "Translation time for 1000 sentences: 69.75 seconds\n"
          ]
        }
      ],
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sample = xval.sample(1000)\n",
        "predicted_sent=[]\n",
        "b_score = []\n",
        "for i,sent in enumerate(sample[\"Italian\"].values):\n",
        "    pred_sent,attention_plot = predict_conc(sent)\n",
        "    predicted_sent.append(pred_sent)\n",
        "    bs = bleu.sentence_bleu([sample[\"eng_out\"].values[i].split()],pred_sent.split())\n",
        "    b_score.append(round(bs,3))\n",
        "sample[\"machine_translation\"] = predicted_sent\n",
        "sample[\"BLEU_score\"] = b_score\n",
        "sample.drop(\"eng_inp\",axis=1,inplace=True)\n",
        "\n",
        "print(\"Average BLEU score of 1000 sample translations:\",np.mean(b_score))\n",
        "    \n",
        "end = time.time()\n",
        "\n",
        "print(\"Translation time for 1000 sentences:\",round(end-start,2),\"seconds\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB1jRUqZQ9AM"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIWe80k2KJLm"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"gen_score_model.h5\", monitor='val_loss', \n",
        "                             verbose=1, save_weights_only = True, save_best_only=True, mode='auto',save_freq='epoch')\n",
        "\n",
        "%reload_ext tensorboard\n",
        "import datetime\n",
        "log_dir = \"log3/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "callbacks=[checkpoint,tensorboard_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kN9ZWViQNMB"
      },
      "outputs": [],
      "source": [
        "#Compile and train your model on concat scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "#Compile and train your model on general scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "batch_size=1\n",
        "inp_vocab_size=voc_size_ita+1\n",
        "out_vocab_size=voc_size_eng+1\n",
        "embedding_size=100\n",
        "lstm_size=64\n",
        "enc_input_length=max_len_ita\n",
        "dec_input_length=max_len_eng\n",
        "dec_units=64\n",
        "score_fun='general'\n",
        "att_units=64\n",
        "att_model_gen = encoder_decoder(batch_size,inp_vocab_size,embedding_size,lstm_size,enc_input_length,\n",
        "                out_vocab_size, dec_input_length, dec_units ,score_fun ,att_units)\n",
        "att_model_gen.compile(optimizer=optimizer,loss=loss_function)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff1lV0ITM6_p",
        "scrolled": true,
        "outputId": "433e3d1a-beb9-4ed4-8e1e-73a87d98cd4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "4411/4411 [==============================] - 1489s 337ms/step - loss: 1.2681 - val_loss: 1.0091\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.00913, saving model to gen_score_model.h5\n",
            "Epoch 2/20\n",
            "4411/4411 [==============================] - 1483s 336ms/step - loss: 0.8837 - val_loss: 0.7867\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.00913 to 0.78667, saving model to gen_score_model.h5\n",
            "Epoch 3/20\n",
            "4411/4411 [==============================] - 1484s 336ms/step - loss: 0.7015 - val_loss: 0.6511\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.78667 to 0.65109, saving model to gen_score_model.h5\n",
            "Epoch 4/20\n",
            "4411/4411 [==============================] - 1498s 340ms/step - loss: 0.5784 - val_loss: 0.5641\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.65109 to 0.56412, saving model to gen_score_model.h5\n",
            "Epoch 5/20\n",
            "4411/4411 [==============================] - 1516s 344ms/step - loss: 0.4884 - val_loss: 0.4983\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.56412 to 0.49834, saving model to gen_score_model.h5\n",
            "Epoch 6/20\n",
            "4411/4411 [==============================] - 1497s 339ms/step - loss: 0.4213 - val_loss: 0.4518\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.49834 to 0.45175, saving model to gen_score_model.h5\n",
            "Epoch 7/20\n",
            "4411/4411 [==============================] - 1483s 336ms/step - loss: 0.3709 - val_loss: 0.4198\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.45175 to 0.41983, saving model to gen_score_model.h5\n",
            "Epoch 8/20\n",
            "4411/4411 [==============================] - 1488s 337ms/step - loss: 0.3323 - val_loss: 0.3963\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.41983 to 0.39631, saving model to gen_score_model.h5\n",
            "Epoch 9/20\n",
            "4411/4411 [==============================] - 1484s 336ms/step - loss: 0.3020 - val_loss: 0.3741\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.39631 to 0.37411, saving model to gen_score_model.h5\n",
            "Epoch 10/20\n",
            "4411/4411 [==============================] - 1498s 340ms/step - loss: 0.2775 - val_loss: 0.3607\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.37411 to 0.36072, saving model to gen_score_model.h5\n",
            "Epoch 11/20\n",
            "4411/4411 [==============================] - 1493s 338ms/step - loss: 0.2574 - val_loss: 0.3452\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.36072 to 0.34516, saving model to gen_score_model.h5\n",
            "Epoch 12/20\n",
            "4411/4411 [==============================] - 1489s 338ms/step - loss: 0.2405 - val_loss: 0.3369\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.34516 to 0.33690, saving model to gen_score_model.h5\n",
            "Epoch 13/20\n",
            "4411/4411 [==============================] - 1490s 338ms/step - loss: 0.2262 - val_loss: 0.3377\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.33690\n",
            "Epoch 14/20\n",
            "4411/4411 [==============================] - 1486s 337ms/step - loss: 0.2138 - val_loss: 0.3233\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.33690 to 0.32332, saving model to gen_score_model.h5\n",
            "Epoch 15/20\n",
            "4411/4411 [==============================] - 1481s 336ms/step - loss: 0.2031 - val_loss: 0.3196\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.32332 to 0.31964, saving model to gen_score_model.h5\n",
            "Epoch 16/20\n",
            "4411/4411 [==============================] - 1484s 336ms/step - loss: 0.1937 - val_loss: 0.3171\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.31964 to 0.31708, saving model to gen_score_model.h5\n",
            "Epoch 17/20\n",
            "4411/4411 [==============================] - 1484s 336ms/step - loss: 0.1854 - val_loss: 0.3149\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.31708 to 0.31491, saving model to gen_score_model.h5\n",
            "Epoch 18/20\n",
            "4411/4411 [==============================] - 1486s 337ms/step - loss: 0.1780 - val_loss: 0.3073\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.31491 to 0.30732, saving model to gen_score_model.h5\n",
            "Epoch 19/20\n",
            "4411/4411 [==============================] - 1486s 337ms/step - loss: 0.1716 - val_loss: 0.3084\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.30732\n",
            "Epoch 20/20\n",
            "4411/4411 [==============================] - 1486s 337ms/step - loss: 0.1656 - val_loss: 0.3023\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.30732 to 0.30228, saving model to gen_score_model.h5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2520c2357c0>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "att_model_gen.fit(train_dataloader,epochs=20,callbacks=callbacks,validation_data=test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9eqLj3IKJLn"
      },
      "outputs": [],
      "source": [
        "def predict_gen(input_sentence):\n",
        "    #A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    inp = tok_ita.texts_to_sequences([input_sentence])\n",
        "    inp = pad_sequences(inp, maxlen=max_len_ita, dtype='int32', padding='post')\n",
        "    #print(\"input_shape\",inp.shape)\n",
        "    #B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    enc_out,enc_h_state,enc_c_state = att_model_gen.layers[0](inp,att_model_gen.encoder.initialize_states(batch_size=1))\n",
        "    #C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "    dec_inp = np.array(tok_eng.word_index['<sos>']).reshape(1,1)\n",
        "    #print(enc_out.shape,enc_h_state.shape,enc_c_state.shape,dec_inp.shape)\n",
        "    dec_stop = tok_eng.word_index['<eos>']\n",
        "    states=[enc_h_state,enc_c_state]\n",
        "    stop_condition=False\n",
        "    sent=''\n",
        "    k=0\n",
        "    output_len = max_len_eng\n",
        "    input_len = max_len_ita\n",
        "    attention_weights_list = []\n",
        "    #print(\"att_plot shape:\",attention_plot.shape)\n",
        "    \n",
        "    for t in range(output_len):\n",
        "        predictions,state_h,state_c,attention_weights,context_vector = att_model_gen.layers[1].OSD(dec_inp,\n",
        "                                                                                                      enc_out,\n",
        "                                                                                                      enc_h_state,enc_c_state)\n",
        "        #print(\"OSD pred shape:\",predictions.shape)\n",
        "        attention_weights_list.append(attention_weights[0,:,0])\n",
        "        \n",
        "        word_ind = np.argmax(predictions,-1)\n",
        "        \n",
        "        pred_str = list(tok_eng.word_index.keys())[int(word_ind-1)]\n",
        "        \n",
        "        sent += ' '+pred_str\n",
        "        k+=1\n",
        "        if k>max_len_eng or int(word_ind) == int(dec_stop):\n",
        "            return sent,np.array(attention_weights_list)\n",
        "        \n",
        "        dec_inp = word_ind.reshape(1,1)\n",
        "        \n",
        "    return sent, np.array(attention_weights_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM0PlBFRKJLn",
        "outputId": "57816b92-2bd2-4771-9c03-822fb2f66e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Italian            loro non torneranno\n",
            "eng_inp    <sos> they will not be back\n",
            "eng_out    they will not be back <eos>\n",
            "Name: 65628, dtype: object\n",
            "====================================================================================================\n",
            "Italian sentence:   loro non torneranno\n",
            "Translated sentence:    they will not be back <eos>\n",
            "Translation time: 0.05 seconds\n",
            "====================================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-50-7524cf7920bc>:16: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "<ipython-input-50-7524cf7920bc>:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(xval.iloc[150])\n",
        "print(\"=\"*100)\n",
        "print(\"Italian sentence:  \",xval['Italian'].values[150])\n",
        "start = time.time()\n",
        "pred_sent,attention_plot = predict_gen(xval['Italian'].values[150])\n",
        "end = time.time()\n",
        "print(\"Translated sentence:  \",pred_sent)\n",
        "print(\"Translation time:\",round(end-start,2),\"seconds\")\n",
        "print(\"=\"*100)\n",
        "plot_attention(attention_plot, xval['Italian'].values[150], pred_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upUBWeSrKJLo",
        "outputId": "a2a25c0f-afd1-4771-c620-c76aed674f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Italian    adesso andate a casa\n",
            "eng_inp    <sos> now go on home\n",
            "eng_out    now go on home <eos>\n",
            "Name: 21216, dtype: object\n",
            "====================================================================================================\n",
            "Italian sentence:   adesso andate a casa\n",
            "Translated sentence:    now go home <eos>\n",
            "Translation time: 0.05 seconds\n",
            "====================================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-50-7524cf7920bc>:16: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "<ipython-input-50-7524cf7920bc>:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(xval.iloc[165])\n",
        "print(\"=\"*100)\n",
        "print(\"Italian sentence:  \",xval['Italian'].values[165])\n",
        "start = time.time()\n",
        "pred_sent,attention_plot = predict_gen(xval['Italian'].values[165])\n",
        "end = time.time()\n",
        "print(\"Translated sentence:  \",pred_sent)\n",
        "print(\"Translation time:\",round(end-start,2),\"seconds\")\n",
        "print(\"=\"*100)\n",
        "plot_attention(attention_plot, xval['Italian'].values[165], pred_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY4meDZyKJLo",
        "outputId": "c2725ffb-1306-4c0b-91f9-f56d9e19b26d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Italian     hai chiesto il nostro aiuto\n",
            "eng_inp    <sos> you asked for our help\n",
            "eng_out    you asked for our help <eos>\n",
            "Name: 130782, dtype: object\n",
            "====================================================================================================\n",
            "Italian sentence:   hai chiesto il nostro aiuto\n",
            "Translated sentence:    did you ask our help <eos>\n",
            "Translation time: 0.06 seconds\n",
            "====================================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-50-7524cf7920bc>:16: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "<ipython-input-50-7524cf7920bc>:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(xval.iloc[202])\n",
        "print(\"=\"*100)\n",
        "print(\"Italian sentence:  \",xval['Italian'].values[202])\n",
        "start = time.time()\n",
        "pred_sent,attention_plot = predict_gen(xval['Italian'].values[202])\n",
        "end = time.time()\n",
        "print(\"Translated sentence:  \",pred_sent)\n",
        "print(\"Translation time:\",round(end-start,2),\"seconds\")\n",
        "print(\"=\"*100)\n",
        "plot_attention(attention_plot, xval['Italian'].values[202], pred_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFGrwDaxKJLo",
        "outputId": "2404afd4-e7b3-449b-e07c-6e1033c7a9cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU score of 1000 sample translations: 0.413175\n",
            "Translation time for 1000 sentences: 64.87 seconds\n"
          ]
        }
      ],
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sample = xval.sample(1000)\n",
        "predicted_sent=[]\n",
        "b_score = []\n",
        "for i,sent in enumerate(sample[\"Italian\"].values):\n",
        "    pred_sent,attention_plot = predict_gen(sent)\n",
        "    predicted_sent.append(pred_sent)\n",
        "    bs = bleu.sentence_bleu([sample[\"eng_out\"].values[i].split()],pred_sent.split())\n",
        "    b_score.append(round(bs,3))\n",
        "sample[\"machine_translation\"] = predicted_sent\n",
        "sample[\"BLEU_score\"] = b_score\n",
        "sample.drop(\"eng_inp\",axis=1,inplace=True)\n",
        "\n",
        "print(\"Average BLEU score of 1000 sample translations:\",np.mean(b_score))\n",
        "    \n",
        "end = time.time()\n",
        "\n",
        "print(\"Translation time for 1000 sentences:\",round(end-start,2),\"seconds\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6U7XfGdKJLo"
      },
      "source": [
        "**OBSERVATIONS:**\n",
        "\n",
        "Average BLEU score of random 1000 translations for various models achieved were as follows:\n",
        "\n",
        "1. Attention encoder decoder model with dot scoring function:\n",
        "   Average BLEU score of 1000 sample translations: 0.4062\n",
        "\n",
        "2. Attention encoder decoder model with concat scoring function:\n",
        "   Average BLEU score of 1000 sample translations: 0.1100\n",
        "   \n",
        "3. Attention encoder decoder model with general scoring function:\n",
        "   Average BLEU score of 1000 sample translations: 0.4131\n",
        "   \n",
        "As we can observe attention encoder-decoder model with concat scoring function performs the worst with a average BLEU score of just 0.11 for 1000 translations, whereas those with dot scoring and general scoring perform well out of which the model with general scoring function has the highest BLEU score of 0.4131.\n",
        "\n",
        "Validation loss for model  general scoring is also lowest at 0.3023 compared to 0.7146 val_loss of model with concat scoring and 0.3215 val_loss of model with dot scoring function.\n",
        "\n",
        "Model with concat scoring is overfitting as training loss is good but validation loss is high."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}